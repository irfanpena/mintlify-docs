---
title: Perception Layer
sidebarTitle: Perception
description: Learn how to configure perception layer.
---

The **Perception Layer** in Tavus enhances AI personas with real-time visual understanding through webcam and screen share feeds. It enables the AI to track visual cues, assess user behavior, and trigger actions that allow for natural and deeply human interactions.

## Raven Overview
**Raven-0** is Tavusâ€™s advanced real-time multimodal perception model. It mimics human-like visual awareness using a dual-track vision system:

- **Ambient Perception**: Constant low-level visual scanning that helps Raven understand user identity, emotions, and environment.
  - Includes default queries like user appearance and emotional state.
  - Supports custom passive queries with [`ambient_awareness_queries`](#2-add-ambient-awareness-queries).
- **Active Perception**: On-demand visual analysis triggered by specific needs.
  - Uses speculative execution to minimize latency.



## Configuring the Perception Layer

### 1. Select the `perception_model`

`raven-0` is the default and recommended model for the Perception Layer. You can use it as is or customize it further to suit your needs.

<Note>
**Screen Share Vision**: When using `raven-0`, screen share feature is enabled by default without additional configuration.
</Note>

```json
"layers": {
  "perception": {
    "perception_model": "raven-0"
  }
}
```

### 2. Add `ambient_awareness_queries`
Use this field to define the custom passive visual prompts `raven-0` should always monitor for.
<Note>
This field is available only for `raven-0`.
</Note>
```json
"ambient_awareness_queries": [
  "Is the user wearing a bright outfit?"
]
```

<Tip>
Use this to make the AI continuously aware of visual context without needing user input.
</Tip>

### 3. Define the `perception_tool_prompt`

Tell `raven-0` when and how to trigger tools based on what it sees.
<Note>
This field is available only for `raven-0`.
</Note>
```json
"perception_tool_prompt":
  "You have a tool to notify the system when a bright outfit is detected, named `notify_if_bright_outfit_shown`. You MUST use this tool when a bright outfit is detected."
```

### 4. Register `perception_tools`

These are callable functions that can be triggered by `raven-0` when specific visual conditions are met.
<Note>
This field is available only for `raven-0`.
</Note>
```json
"perception_tools": [
  {
    "type": "function",
    "function": {
      "name": "notify_if_bright_outfit_shown",
      "description": "Use this function when a bright outfit is detected in the image with high confidence",
      "parameters": {
        "type": "object",
        "properties": {
          "outfit_color": {
            "type": "string",
            "description": "Best guess on what color of outfit it is"
          }
        },
        "required": ["outfit_color"]
      }
    }
  }
]
```

<Note>
Perception tools require both a `type` and detailed `parameters` schema.
</Note>

### End-of-call Perception Analysis

If your persona uses `raven-0`, it will automatically generate a visual summary at the end of a call. This summary includes all detected visual artifacts and can be sent as:

- A [Perception Analysis](https://docs.tavus.io/sections/event-schemas/conversation-perception-analysis) event

- A [conversation callback](https://docs.tavus.io/sections/conversational-video-interface/conversation-callbacks) (if specified)

## Example Use Case

This persona identifies when a user is wearing a bright outfit and triggers an internal action.
<Tip>
**Recommendation:**

Use the full **CVI end-to-end pipeline** for optimal performance and lowest latency.
</Tip>
```bash
curl -X POST https://tavusapi.com/v2/personas \
  -H "x-api-key: <YOUR_API_KEY>" \
  -H "Content-Type: application/json" \
  -d '{
    "persona_name": "Fashion Advisor",
    "system_prompt": "As a Fashion Advisor, you specialize in offering tailored fashion advice.",
    "pipeline_mode": "full",
    "context": "You're having a video conversation with a client about their outfit.",
    "default_replica_id": "r79e1c033f",
    "layers": {
      "perception": {
        "perception_model": "raven-0",
        "ambient_awareness_queries": [
          "Is the user wearing a bright outfit?"
        ],
        "perception_tool_prompt":
          "You have a tool to notify the system when a bright outfit is detected, named `notify_if_bright_outfit_shown`. You MUST use this tool when a bright outfit is detected.",
        "perception_tools": [
          {
            "type": "function",
            "function": {
              "name": "notify_if_bright_outfit_shown",
              "description": "Use this function when a bright outfit is detected in the image with high confidence",
              "parameters": {
                "type": "object",
                "properties": {
                  "outfit_color": {
                    "type": "string",
                    "description": "Best guess on what color of outfit it is"
                  }
                },
                "required": ["outfit_color"]
              }
            }
          }
        ]
      },
      "stt": {
        "stt_engine": "tavus-advanced",
        "participant_pause_sensitivity": "high",
        "participant_interrupt_sensitivity": "high",
        "smart_turn_detection": true
      }
    }
  }'
```
<Note>
For more information please see the [Create a Persona](https://docs.tavus.io/api-reference/personas/create-persona) endpoint.
</Note>

### Behavioral Flow

- **Visual Detection**: `raven-0` monitors for defined visual queries (e.g., bright outfit).

- **Tool Prompting**: Guides the AI to act using perception tools.

- **Tool Execution**: Invokes tools (e.g., `notify_if_bright_outfit_shown`) with context-specific parameters.

